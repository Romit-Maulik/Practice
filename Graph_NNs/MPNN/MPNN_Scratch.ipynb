{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(10)\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of turbines\n",
    "num_turbines = 25\n",
    "\n",
    "# import data\n",
    "configs = os.listdir('./SCADA_sectors_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scada_data_extractor(fname):\n",
    "    raw_data = np.loadtxt(fname,delimiter=',',skiprows=1)\n",
    "    \n",
    "    # Time\n",
    "    time_data = raw_data[:,0:1]\n",
    "    \n",
    "    # Wind data - this will be added in later\n",
    "    wd = raw_data[:,1:2] \n",
    "    \n",
    "    # wind speeds at each turbine\n",
    "    windspeed_data = raw_data[:,2:2+num_turbines].reshape(-1,25,1)\n",
    "    \n",
    "    # TI at each turbine\n",
    "    ti_data = raw_data[:,2+num_turbines:2+2*num_turbines].reshape(-1,25,1)\n",
    "    \n",
    "    # power data at each turbine\n",
    "    p_data = raw_data[:,2+2*num_turbines:2+3*num_turbines].reshape(-1,25,1)\n",
    "    \n",
    "    # x data at each turbine\n",
    "    x_data = raw_data[:,2+3*num_turbines:2+5*num_turbines:2].reshape(-1,25,1)\n",
    "    \n",
    "    # y data at each turbine\n",
    "    y_data = raw_data[:,2+3*num_turbines+1:2+5*num_turbines+1:2].reshape(-1,25,1)\n",
    "    \n",
    "    # copy over wd data \n",
    "    wd_data = np.zeros(shape=(raw_data.shape[0],25,1))\n",
    "    wd_data[:,:,0] = wd[:,None,0]\n",
    "    \n",
    "    feature_data_ip = np.concatenate((wd_data,windspeed_data,ti_data,x_data,y_data),axis=-1)\n",
    "    \n",
    "    return feature_data_ip, p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amat_list= []\n",
    "pos_list = []\n",
    "ip_list = []\n",
    "op_list = []\n",
    "\n",
    "for config in configs:\n",
    "    fname = './SCADA_sectors_v3/'+config+'/SCADA.csv'\n",
    "    feature_data_ip, feature_data_op = scada_data_extractor(fname)\n",
    "    \n",
    "    ip_list.append(feature_data_ip)\n",
    "    op_list.append(feature_data_op)\n",
    "           \n",
    "    amat = np.loadtxt('./SCADA_sectors_v3/'+config+'/node_interactions.csv',delimiter=',')\n",
    "    pos = np.loadtxt('./SCADA_sectors_v3/'+config+'/positions.csv',delimiter=',',skiprows=1)\n",
    "    \n",
    "    for i in range(feature_data_ip.shape[0]):\n",
    "        amat_list.append(amat.copy())\n",
    "        pos_list.append(pos.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_list[0]\n",
    "op_data = op_list[0]\n",
    "\n",
    "for i in range(1,len(ip_list)):\n",
    "    temp = ip_list[i]\n",
    "    ip_data = np.concatenate((ip_data,temp),axis=0)\n",
    "    \n",
    "    temp = op_list[i]\n",
    "    op_data = np.concatenate((op_data,temp),axis=0)\n",
    "\n",
    "amat_data = np.asarray(amat_list)\n",
    "pos_data = np.asarray(pos_list) # Ignoring pos_data for now but that can be add to ip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10181, 625, 1)\n"
     ]
    }
   ],
   "source": [
    "amat_data = amat_data.reshape(-1,amat_data.shape[1]*amat_data.shape[2],1)\n",
    "print(amat_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data.astype('float32')\n",
    "amat_data = amat_data.astype('float32')\n",
    "op_data = op_data[:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message_Passer(tf.keras.layers.Layer):\n",
    "    def __init__(self, node_dim):\n",
    "        super(Message_Passer, self).__init__()\n",
    "        self.node_dim = node_dim\n",
    "        self.nn = tf.keras.layers.Dense(units=self.node_dim*self.node_dim, activation = tf.nn.relu)\n",
    "      \n",
    "    def call(self, node_j, edge_ij):\n",
    "        \n",
    "        # Embed the edge as a matrix\n",
    "        A = self.nn(edge_ij)\n",
    "        \n",
    "        # Reshape so matrix mult can be done\n",
    "        A = tf.reshape(A, [-1, self.node_dim, self.node_dim])\n",
    "        node_j = tf.reshape(node_j, [-1, self.node_dim, 1])\n",
    "        \n",
    "        # Multiply edge matrix by node and shape into message list\n",
    "        messages = tf.linalg.matmul(A, node_j)\n",
    "        messages = tf.reshape(messages, [-1, tf.shape(edge_ij)[1], self.node_dim])\n",
    "\n",
    "        return messages\n",
    "    \n",
    "class Message_Agg(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Message_Agg, self).__init__()\n",
    "    \n",
    "    def call(self, messages):\n",
    "        return tf.math.reduce_sum(messages, 2)\n",
    "    \n",
    "\n",
    "class Update_Func_GRU(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim):\n",
    "        super(Update_Func_GRU, self).__init__()\n",
    "        self.concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.GRU = tf.keras.layers.GRU(state_dim)\n",
    "        \n",
    "    def call(self, old_state, agg_messages):\n",
    "    \n",
    "        # Remember node dim\n",
    "        n_nodes  = tf.shape(old_state)[1]\n",
    "        node_dim = tf.shape(old_state)[2]\n",
    "        \n",
    "        # Reshape so GRU can be applied, concat so old_state and messages are in sequence\n",
    "        old_state = tf.reshape(old_state, [-1, 1, tf.shape(old_state)[-1]])\n",
    "        agg_messages = tf.reshape(agg_messages, [-1, 1, tf.shape(agg_messages)[-1]])\n",
    "        concat = self.concat_layer([old_state, agg_messages])\n",
    "        \n",
    "        # Apply GRU and then reshape so it can be returned\n",
    "        activation = self.GRU(concat)\n",
    "        activation = tf.reshape(activation, [-1, n_nodes, node_dim])\n",
    "        \n",
    "        return activation\n",
    "    \n",
    "# Define the final output layer \n",
    "class Output_Regressor(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_nodes, intermediate_dim):\n",
    "        super(Output_Regressor, self).__init__()\n",
    "        self.concat_layer = tf.keras.layers.Concatenate()\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(units=intermediate_dim, activation=tf.nn.relu)\n",
    "        self.hidden_layer_2 = tf.keras.layers.Dense(units=intermediate_dim, activation=tf.nn.relu)\n",
    "        self.hidden_layer_3 = tf.keras.layers.Dense(units=1, activation=tf.nn.relu)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=n_nodes, activation=None)\n",
    "\n",
    "        \n",
    "    def call(self, nodes, edges):\n",
    "                   \n",
    "        # Remember node dims\n",
    "        n_nodes  = tf.shape(nodes)[1]\n",
    "        node_dim = tf.shape(nodes)[2]\n",
    "        \n",
    "        # Tile and reshape to match edges\n",
    "        state_i = tf.reshape(tf.tile(nodes, [1, 1, n_nodes]),[-1,n_nodes*n_nodes, node_dim ])\n",
    "        state_j = tf.tile(nodes, [1, n_nodes, 1])\n",
    "        \n",
    "        # concat edges and nodes and apply MLP\n",
    "        concat = self.concat_layer([state_i, edges, state_j])\n",
    "                \n",
    "        activation_1 = self.hidden_layer_1(concat)  \n",
    "        activation_2 = self.hidden_layer_2(activation_1)\n",
    "        activation_3 = self.hidden_layer_3(activation_2)\n",
    "        \n",
    "        output_value = self.output_layer(activation_3[:,:,0])\n",
    "        \n",
    "        return output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a single message passing layer\n",
    "class MP_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim):\n",
    "        super(MP_Layer, self).__init__(self)\n",
    "        self.message_passers  = Message_Passer(node_dim = state_dim) \n",
    "        self.message_aggs    = Message_Agg()\n",
    "        self.update_functions = Update_Func_GRU(state_dim = state_dim)\n",
    "        \n",
    "        self.state_dim = state_dim         \n",
    "\n",
    "    def call(self, nodes, edges, mask):\n",
    "      \n",
    "        n_nodes  = tf.shape(nodes)[1]\n",
    "        node_dim = tf.shape(nodes)[2]\n",
    "        \n",
    "        state_j = tf.tile(nodes, [1, n_nodes, 1])\n",
    "\n",
    "        messages  = self.message_passers(state_j, edges)\n",
    "\n",
    "        # Do this to ignore messages from non-existant nodes\n",
    "        masked =  tf.math.multiply(messages, mask)\n",
    "        \n",
    "        masked = tf.reshape(masked, [tf.shape(messages)[0], n_nodes, n_nodes, node_dim])\n",
    "\n",
    "        agg_m = self.message_aggs(masked)\n",
    "        \n",
    "        updated_nodes = self.update_functions(nodes, agg_m)\n",
    "        \n",
    "        nodes_out = updated_nodes\n",
    "        # Batch norm seems not to work. \n",
    "        #nodes_out = self.batch_norm(updated_nodes)\n",
    "        \n",
    "        return nodes_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_input = tf.keras.Input(shape=(None,), name='adj_input')\n",
    "nod_input = tf.keras.Input(shape=(None,), name='nod_input')\n",
    "class MPNN(tf.keras.Model):\n",
    "    def __init__(self, n_nodes, out_int_dim, state_dim, T):\n",
    "        super(MPNN, self).__init__(self)   \n",
    "        self.T = T\n",
    "        self.embed = tf.keras.layers.Dense(units=state_dim, activation=tf.nn.relu)\n",
    "        self.MP = MP_Layer(state_dim)     \n",
    "        self.edge_regressor  = Output_Regressor(n_nodes,out_int_dim)\n",
    "        #self.batch_norm = tf.keras.layers.BatchNormalization() \n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "      \n",
    "        nodes = inputs[0]\n",
    "        edges = inputs[1]\n",
    "\n",
    "        # Get distances, and create mask wherever 0 (i.e. non-existant nodes)\n",
    "        # This also masks node self-interactions...\n",
    "        # This assumes distance is last\n",
    "        len_edges = tf.shape(edges)[-1]\n",
    "        \n",
    "        _, x = tf.split(edges, [len_edges -1, 1], 2)\n",
    "        mask =  tf.where(tf.equal(x, 0), x, tf.ones_like(x))\n",
    "        \n",
    "        # Embed node to be of the chosen node dimension (you can also just pad)\n",
    "        nodes = self.embed(nodes) \n",
    "        \n",
    "        #nodes = self.batch_norm(nodes)\n",
    "        # Run the T message passing steps\n",
    "        for mp in range(self.T):\n",
    "            nodes =  self.MP(nodes, edges, mask)\n",
    "        \n",
    "        # Regress the output values\n",
    "        con_edges = self.edge_regressor(nodes, edges)\n",
    "        \n",
    "        \n",
    "        return con_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "    reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(nums, preds)))\n",
    "\n",
    "    return reconstruction_error\n",
    "\n",
    "def log_mse(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "\n",
    "    reconstruction_error = tf.math.log(tf.reduce_mean(tf.square(tf.subtract(nums, preds))))\n",
    "\n",
    "\n",
    "    return reconstruction_error\n",
    "\n",
    "def mae(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "\n",
    "    reconstruction_error = tf.reduce_mean(tf.abs(tf.subtract(nums, preds)))\n",
    "\n",
    "\n",
    "    return reconstruction_error\n",
    "\n",
    "def log_mae(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "    reconstruction_error = tf.math.log(tf.reduce_mean(tf.abs(tf.subtract(nums, preds))))\n",
    "\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = learning_rate\n",
    "    drop = 0.1\n",
    "    epochs_drop = 20.0\n",
    "    lrate = initial_lrate * np.power(drop,  \n",
    "           np.floor((epoch)/epochs_drop))\n",
    "    tf.print(\"Learning rate: \", lrate)\n",
    "    return lrate\n",
    "\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 15, restore_best_weights=True)\n",
    "\n",
    "#lrate  =  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "#                              patience=5, min_lr=0.00001, verbose = 1)\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = MPNN(n_nodes=25, out_int_dim = 32, state_dim = 32, T = 3)\n",
    "mpnn.compile(opt, log_mae, metrics = [mae, log_mse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call network once to build weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 25), dtype=float32, numpy=\n",
       "array([[-0.00675847, -0.01622743,  0.0053461 , -0.00250022,  0.00033265,\n",
       "        -0.00907387, -0.01168793, -0.00800502, -0.00473904, -0.0045182 ,\n",
       "        -0.00100265,  0.0040614 ,  0.00327675, -0.00491253, -0.01268168,\n",
       "         0.01066714, -0.02237931,  0.00214788,  0.01410059,  0.00194093,\n",
       "        -0.00308206,  0.00755948,  0.01235848, -0.00216651, -0.00664559],\n",
       "       [-0.00671818, -0.01627544,  0.00525346, -0.00254929,  0.00039963,\n",
       "        -0.00917484, -0.01164242, -0.00802445, -0.00472527, -0.00452508,\n",
       "        -0.00101762,  0.0040253 ,  0.00330114, -0.00492937, -0.01258837,\n",
       "         0.01071505, -0.02236227,  0.00208531,  0.01416406,  0.001931  ,\n",
       "        -0.00306422,  0.00751599,  0.01241984, -0.00219275, -0.00665756],\n",
       "       [-0.0068213 , -0.01632321,  0.00541178, -0.00250969,  0.00031634,\n",
       "        -0.00910692, -0.01176503, -0.00802546, -0.00477567, -0.00449708,\n",
       "        -0.00100843,  0.0040578 ,  0.00322756, -0.00494221, -0.01280022,\n",
       "         0.01072986, -0.02253353,  0.00214181,  0.01421063,  0.00193635,\n",
       "        -0.00316918,  0.00758333,  0.0123768 , -0.00222574, -0.00668361],\n",
       "       [-0.00683591, -0.01635119,  0.00550337, -0.00248085,  0.00029156,\n",
       "        -0.00910893, -0.01178568, -0.00801125, -0.00479176, -0.00449315,\n",
       "        -0.00101096,  0.00404524,  0.00321403, -0.00495184, -0.01287831,\n",
       "         0.01072045, -0.02259875,  0.00216689,  0.01422558,  0.00193262,\n",
       "        -0.00319627,  0.00757236,  0.01237974, -0.00222095, -0.00670066],\n",
       "       [-0.00676674, -0.01625013,  0.005326  , -0.00251809,  0.00037521,\n",
       "        -0.00911718, -0.01169407, -0.00798189, -0.00474284, -0.00452733,\n",
       "        -0.00106328,  0.00403697,  0.00327764, -0.00491856, -0.01263226,\n",
       "         0.01068586, -0.02240285,  0.00209606,  0.01410114,  0.00196826,\n",
       "        -0.00310211,  0.00753392,  0.01237644, -0.00218475, -0.00665653],\n",
       "       [-0.00683352, -0.01631168,  0.00546417, -0.0024803 ,  0.00031198,\n",
       "        -0.00908255, -0.01174778, -0.00800333, -0.0047734 , -0.00447632,\n",
       "        -0.0009897 ,  0.00406634,  0.00321745, -0.00493215, -0.01286297,\n",
       "         0.01068323, -0.0225639 ,  0.00217583,  0.01420795,  0.00192469,\n",
       "        -0.00318756,  0.00758747,  0.01235448, -0.00222795, -0.00667604],\n",
       "       [-0.00684429, -0.01640676,  0.00549868, -0.00248053,  0.0002745 ,\n",
       "        -0.00916344, -0.01180679, -0.00803851, -0.00480902, -0.0044758 ,\n",
       "        -0.00100809,  0.0040441 ,  0.00320212, -0.00498771, -0.01296036,\n",
       "         0.01074617, -0.02268344,  0.0021557 ,  0.01432207,  0.00189496,\n",
       "        -0.00319981,  0.00759295,  0.0124276 , -0.00226729, -0.00674374],\n",
       "       [-0.00663863, -0.01611948,  0.00514768, -0.00257917,  0.00027265,\n",
       "        -0.00884042, -0.01173225, -0.00803299, -0.00466753, -0.00458703,\n",
       "        -0.00108391,  0.00394982,  0.00333788, -0.00494432, -0.01248459,\n",
       "         0.01072205, -0.02217376,  0.00210801,  0.01394977,  0.00196631,\n",
       "        -0.00306851,  0.00750424,  0.01226903, -0.0020641 , -0.00660309],\n",
       "       [-0.00682121, -0.01633406,  0.00545915, -0.00250114,  0.00031772,\n",
       "        -0.00910222, -0.01176063, -0.00800187, -0.00476739, -0.00449784,\n",
       "        -0.00101672,  0.00403068,  0.00322508, -0.00494634, -0.01283943,\n",
       "         0.01072342, -0.0225714 ,  0.00215494,  0.01421181,  0.0019244 ,\n",
       "        -0.00318107,  0.00755406,  0.01237911, -0.00222028, -0.00668943],\n",
       "       [-0.00685219, -0.01638135,  0.0054977 , -0.00250226,  0.00027393,\n",
       "        -0.00909864, -0.01180921, -0.00804938, -0.00476567, -0.00446976,\n",
       "        -0.00097381,  0.00405569,  0.00319075, -0.00496888, -0.01296044,\n",
       "         0.01070441, -0.02266172,  0.00217735,  0.0143029 ,  0.00191621,\n",
       "        -0.00321811,  0.0076089 ,  0.01236878, -0.00228198, -0.00673714]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn.call([ip_data[:10],amat_data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "valid_size = 1000\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 18s - loss: -5.3202e-01 - mae: 0.5876 - log_mse: -7.4776e-01 - val_loss: -6.5605e-01 - val_mae: 0.5206 - val_log_mse: -9.8700e-01\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -9.2450e-01 - mae: 0.3967 - log_mse: -1.5102e+00 - val_loss: -1.1033e+00 - val_mae: 0.3316 - val_log_mse: -2.0044e+00\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.1592e+00 - mae: 0.3135 - log_mse: -2.0869e+00 - val_loss: -1.1502e+00 - val_mae: 0.3189 - val_log_mse: -2.0306e+00\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.3361e+00 - mae: 0.2626 - log_mse: -2.2675e+00 - val_loss: -1.2060e+00 - val_mae: 0.3013 - val_log_mse: -2.0726e+00\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.4214e+00 - mae: 0.2414 - log_mse: -2.3748e+00 - val_loss: -1.3062e+00 - val_mae: 0.2737 - val_log_mse: -2.2504e+00\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 12s - loss: -1.5094e+00 - mae: 0.2209 - log_mse: -2.5439e+00 - val_loss: -1.4213e+00 - val_mae: 0.2455 - val_log_mse: -2.3670e+00\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.5837e+00 - mae: 0.2057 - log_mse: -2.6431e+00 - val_loss: -1.4120e+00 - val_mae: 0.2480 - val_log_mse: -2.2886e+00\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6249e+00 - mae: 0.1975 - log_mse: -2.7033e+00 - val_loss: -1.4203e+00 - val_mae: 0.2468 - val_log_mse: -2.2667e+00\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6445e+00 - mae: 0.1928 - log_mse: -2.7352e+00 - val_loss: -1.4976e+00 - val_mae: 0.2284 - val_log_mse: -2.4405e+00\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6665e+00 - mae: 0.1892 - log_mse: -2.7504e+00 - val_loss: -1.4282e+00 - val_mae: 0.2435 - val_log_mse: -2.4367e+00\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6392e+00 - mae: 0.1942 - log_mse: -2.7187e+00 - val_loss: -1.4995e+00 - val_mae: 0.2278 - val_log_mse: -2.4077e+00\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6907e+00 - mae: 0.1848 - log_mse: -2.7867e+00 - val_loss: -1.5221e+00 - val_mae: 0.2225 - val_log_mse: -2.5023e+00\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6956e+00 - mae: 0.1850 - log_mse: -2.7993e+00 - val_loss: -1.5211e+00 - val_mae: 0.2226 - val_log_mse: -2.5108e+00\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.7013e+00 - mae: 0.1826 - log_mse: -2.7907e+00 - val_loss: -1.5548e+00 - val_mae: 0.2159 - val_log_mse: -2.4760e+00\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6774e+00 - mae: 0.1870 - log_mse: -2.7448e+00 - val_loss: -1.5268e+00 - val_mae: 0.2214 - val_log_mse: -2.4916e+00\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6646e+00 - mae: 0.1906 - log_mse: -2.7315e+00 - val_loss: -1.4599e+00 - val_mae: 0.2355 - val_log_mse: -2.5272e+00\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.6938e+00 - mae: 0.1843 - log_mse: -2.8144e+00 - val_loss: -1.5456e+00 - val_mae: 0.2176 - val_log_mse: -2.5016e+00\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.7200e+00 - mae: 0.1791 - log_mse: -2.8409e+00 - val_loss: -1.5605e+00 - val_mae: 0.2145 - val_log_mse: -2.5408e+00\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.7295e+00 - mae: 0.1783 - log_mse: -2.8015e+00 - val_loss: -1.5589e+00 - val_mae: 0.2145 - val_log_mse: -2.4740e+00\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 - 11s - loss: -1.7243e+00 - mae: 0.1788 - log_mse: -2.8146e+00 - val_loss: -1.4771e+00 - val_mae: 0.2326 - val_log_mse: -2.4771e+00\n",
      "Epoch 21/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.6825e+00 - mae: 0.1876 - log_mse: -2.7486e+00 - val_loss: -1.5680e+00 - val_mae: 0.2128 - val_log_mse: -2.4507e+00\n",
      "Epoch 22/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7519e+00 - mae: 0.1734 - log_mse: -2.8287e+00 - val_loss: -1.5790e+00 - val_mae: 0.2106 - val_log_mse: -2.5369e+00\n",
      "Epoch 23/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7693e+00 - mae: 0.1715 - log_mse: -2.9011e+00 - val_loss: -1.5800e+00 - val_mae: 0.2104 - val_log_mse: -2.5205e+00\n",
      "Epoch 24/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7691e+00 - mae: 0.1714 - log_mse: -2.8671e+00 - val_loss: -1.5781e+00 - val_mae: 0.2107 - val_log_mse: -2.5200e+00\n",
      "Epoch 25/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7750e+00 - mae: 0.1705 - log_mse: -2.8976e+00 - val_loss: -1.5773e+00 - val_mae: 0.2109 - val_log_mse: -2.5136e+00\n",
      "Epoch 26/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7728e+00 - mae: 0.1705 - log_mse: -2.8707e+00 - val_loss: -1.5806e+00 - val_mae: 0.2103 - val_log_mse: -2.5160e+00\n",
      "Epoch 27/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7655e+00 - mae: 0.1714 - log_mse: -2.8869e+00 - val_loss: -1.5798e+00 - val_mae: 0.2104 - val_log_mse: -2.5116e+00\n",
      "Epoch 28/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7723e+00 - mae: 0.1700 - log_mse: -2.8813e+00 - val_loss: -1.5806e+00 - val_mae: 0.2102 - val_log_mse: -2.5132e+00\n",
      "Epoch 29/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7781e+00 - mae: 0.1703 - log_mse: -2.9054e+00 - val_loss: -1.5814e+00 - val_mae: 0.2101 - val_log_mse: -2.5055e+00\n",
      "Epoch 30/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7757e+00 - mae: 0.1696 - log_mse: -2.8759e+00 - val_loss: -1.5800e+00 - val_mae: 0.2104 - val_log_mse: -2.5133e+00\n",
      "Epoch 31/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7813e+00 - mae: 0.1686 - log_mse: -2.8903e+00 - val_loss: -1.5801e+00 - val_mae: 0.2103 - val_log_mse: -2.5063e+00\n",
      "Epoch 32/100\n",
      "Learning rate:  0.0001\n",
      "8/8 - 11s - loss: -1.7838e+00 - mae: 0.1687 - log_mse: -2.9037e+00 - val_loss: -1.5797e+00 - val_mae: 0.2104 - val_log_mse: -2.5177e+00\n",
      "Epoch 33/100\n",
      "Learning rate:  0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ee1b68adaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mpnn.fit([ip_data[:train_size],amat_data[:train_size]], y = op_data[:train_size], batch_size = batch_size, epochs = epochs, \n\u001b[1;32m      2\u001b[0m          \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          validation_data = ([ip_data[train_size:train_size+valid_size],amat_data[train_size:train_size+valid_size]],op_data[train_size:train_size+valid_size]) )\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mpnn.fit([ip_data[:train_size],amat_data[:train_size]], y = op_data[:train_size], batch_size = batch_size, epochs = epochs, \n",
    "         callbacks = [lrate, stop_early], use_multiprocessing = False, initial_epoch = 0, verbose = 2, \n",
    "         validation_data = ([ip_data[train_size:train_size+valid_size],amat_data[train_size:train_size+valid_size]],op_data[train_size:train_size+valid_size]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
