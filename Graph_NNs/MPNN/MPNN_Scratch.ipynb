{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(10)\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of turbines\n",
    "num_turbines = 25\n",
    "\n",
    "# import data\n",
    "configs = os.listdir('./SCADA_sectors_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scada_data_extractor(fname):\n",
    "    raw_data = np.loadtxt(fname,delimiter=',',skiprows=1)\n",
    "    \n",
    "    # Time\n",
    "    time_data = raw_data[:,0:1]\n",
    "    \n",
    "    # Wind data - this will be added in later\n",
    "    wd = raw_data[:,1:2] \n",
    "    \n",
    "    # wind speeds at each turbine\n",
    "    windspeed_data = raw_data[:,2:2+num_turbines].reshape(-1,25,1)\n",
    "    \n",
    "    # TI at each turbine\n",
    "    ti_data = raw_data[:,2+num_turbines:2+2*num_turbines].reshape(-1,25,1)\n",
    "    \n",
    "    # power data at each turbine\n",
    "    p_data = raw_data[:,2+2*num_turbines:2+3*num_turbines].reshape(-1,25,1)\n",
    "    \n",
    "    # x data at each turbine\n",
    "    x_data = raw_data[:,2+3*num_turbines:2+5*num_turbines:2].reshape(-1,25,1)\n",
    "    \n",
    "    # y data at each turbine\n",
    "    y_data = raw_data[:,2+3*num_turbines+1:2+5*num_turbines+1:2].reshape(-1,25,1)\n",
    "    \n",
    "    # copy over wd data \n",
    "    wd_data = np.zeros(shape=(raw_data.shape[0],25,1))\n",
    "    wd_data[:,:,0] = wd[:,None,0]\n",
    "    \n",
    "    feature_data_ip = np.concatenate((wd_data,windspeed_data,ti_data,x_data,y_data),axis=-1)\n",
    "    \n",
    "    return feature_data_ip, p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amat_list= []\n",
    "pos_list = []\n",
    "ip_list = []\n",
    "op_list = []\n",
    "\n",
    "for config in configs:\n",
    "    fname = './SCADA_sectors_v3/'+config+'/SCADA.csv'\n",
    "    feature_data_ip, feature_data_op = scada_data_extractor(fname)\n",
    "    \n",
    "    ip_list.append(feature_data_ip)\n",
    "    op_list.append(feature_data_op)\n",
    "           \n",
    "    amat = np.loadtxt('./SCADA_sectors_v3/'+config+'/node_interactions.csv',delimiter=',')\n",
    "    pos = np.loadtxt('./SCADA_sectors_v3/'+config+'/positions.csv',delimiter=',',skiprows=1)\n",
    "    \n",
    "    for i in range(feature_data_ip.shape[0]):\n",
    "        amat_list.append(amat.copy())\n",
    "        pos_list.append(pos.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_list[0]\n",
    "op_data = op_list[0]\n",
    "\n",
    "for i in range(1,len(ip_list)):\n",
    "    temp = ip_list[i]\n",
    "    ip_data = np.concatenate((ip_data,temp),axis=0)\n",
    "    \n",
    "    temp = op_list[i]\n",
    "    op_data = np.concatenate((op_data,temp),axis=0)\n",
    "\n",
    "amat_data = np.asarray(amat_list)\n",
    "pos_data = np.asarray(pos_list) # Ignoring pos_data for now but that can be add to ip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10181, 625, 1)\n"
     ]
    }
   ],
   "source": [
    "amat_data = amat_data.reshape(-1,amat_data.shape[1]*amat_data.shape[2],1)\n",
    "print(amat_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data.astype('float32')\n",
    "amat_data = amat_data.astype('float32')\n",
    "op_data = op_data[:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do train-valid-test split and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_points = ip_data.shape[0]\n",
    "train_points = int(0.7*num_data_points)\n",
    "valid_points = int(0.1*num_data_points)\n",
    "\n",
    "idx = np.arange(num_data_points)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "ip_data_train = ip_data[idx[:train_points]]\n",
    "op_data_train = op_data[idx[:train_points]]\n",
    "amat_data_train = amat_data[idx[:train_points]]\n",
    "\n",
    "ip_data_valid = ip_data[idx[train_points:train_points+valid_points]]\n",
    "op_data_valid = op_data[idx[train_points:train_points+valid_points]]\n",
    "amat_data_valid = amat_data[idx[train_points:train_points+valid_points]]\n",
    "\n",
    "ip_data_test = ip_data[idx[train_points+valid_points:]]\n",
    "op_data_test = op_data[idx[train_points+valid_points:]]\n",
    "amat_data_test = amat_data[idx[train_points+valid_points:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message_Passer(tf.keras.layers.Layer):\n",
    "    def __init__(self, node_dim):\n",
    "        super(Message_Passer, self).__init__()\n",
    "        self.node_dim = node_dim\n",
    "        self.nn = tf.keras.layers.Dense(units=self.node_dim*self.node_dim, activation = tf.nn.relu)\n",
    "      \n",
    "    def call(self, node_j, edge_ij):\n",
    "        \n",
    "        # Embed the edge as a matrix\n",
    "        A = self.nn(edge_ij)\n",
    "        \n",
    "        # Reshape so matrix mult can be done\n",
    "        A = tf.reshape(A, [-1, self.node_dim, self.node_dim])\n",
    "        node_j = tf.reshape(node_j, [-1, self.node_dim, 1])\n",
    "        \n",
    "        # Multiply edge matrix by node and shape into message list\n",
    "        messages = tf.linalg.matmul(A, node_j)\n",
    "        messages = tf.reshape(messages, [-1, tf.shape(edge_ij)[1], self.node_dim])\n",
    "\n",
    "        return messages\n",
    "    \n",
    "class Message_Agg(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Message_Agg, self).__init__()\n",
    "    \n",
    "    def call(self, messages):\n",
    "        return tf.math.reduce_sum(messages, 2)\n",
    "    \n",
    "\n",
    "class Update_Func_GRU(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim):\n",
    "        super(Update_Func_GRU, self).__init__()\n",
    "        self.concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.GRU = tf.keras.layers.GRU(state_dim)\n",
    "        \n",
    "    def call(self, old_state, agg_messages):\n",
    "    \n",
    "        # Remember node dim\n",
    "        n_nodes  = tf.shape(old_state)[1]\n",
    "        node_dim = tf.shape(old_state)[2]\n",
    "        \n",
    "        # Reshape so GRU can be applied, concat so old_state and messages are in sequence\n",
    "        old_state = tf.reshape(old_state, [-1, 1, tf.shape(old_state)[-1]])\n",
    "        agg_messages = tf.reshape(agg_messages, [-1, 1, tf.shape(agg_messages)[-1]])\n",
    "        concat = self.concat_layer([old_state, agg_messages])\n",
    "        \n",
    "        # Apply GRU and then reshape so it can be returned\n",
    "        activation = self.GRU(concat)\n",
    "        activation = tf.reshape(activation, [-1, n_nodes, node_dim])\n",
    "        \n",
    "        return activation\n",
    "    \n",
    "# Define the final output layer \n",
    "class Output_Regressor(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_nodes, intermediate_dim):\n",
    "        super(Output_Regressor, self).__init__()\n",
    "        self.concat_layer = tf.keras.layers.Concatenate()\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(units=intermediate_dim, activation=tf.nn.relu)\n",
    "        self.hidden_layer_2 = tf.keras.layers.Dense(units=intermediate_dim, activation=tf.nn.relu)\n",
    "        self.hidden_layer_3 = tf.keras.layers.Dense(units=1, activation=tf.nn.relu)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=n_nodes, activation=None)\n",
    "\n",
    "        \n",
    "    def call(self, nodes, edges):\n",
    "                   \n",
    "        # Remember node dims\n",
    "        n_nodes  = tf.shape(nodes)[1]\n",
    "        node_dim = tf.shape(nodes)[2]\n",
    "        \n",
    "        # Tile and reshape to match edges\n",
    "        state_i = tf.reshape(tf.tile(nodes, [1, 1, n_nodes]),[-1,n_nodes*n_nodes, node_dim ])\n",
    "        state_j = tf.tile(nodes, [1, n_nodes, 1])\n",
    "        \n",
    "        # concat edges and nodes and apply MLP\n",
    "        concat = self.concat_layer([state_i, edges, state_j])\n",
    "                \n",
    "        activation_1 = self.hidden_layer_1(concat)  \n",
    "        activation_2 = self.hidden_layer_2(activation_1)\n",
    "        activation_3 = self.hidden_layer_3(activation_2)\n",
    "        \n",
    "        output_value = self.output_layer(activation_3[:,:,0])\n",
    "        \n",
    "        return output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a single message passing layer\n",
    "class MP_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim):\n",
    "        super(MP_Layer, self).__init__(self)\n",
    "        self.message_passers  = Message_Passer(node_dim = state_dim) \n",
    "        self.message_aggs    = Message_Agg()\n",
    "        self.update_functions = Update_Func_GRU(state_dim = state_dim)\n",
    "        \n",
    "        self.state_dim = state_dim         \n",
    "\n",
    "    def call(self, nodes, edges, mask):\n",
    "      \n",
    "        n_nodes  = tf.shape(nodes)[1]\n",
    "        node_dim = tf.shape(nodes)[2]\n",
    "        \n",
    "        state_j = tf.tile(nodes, [1, n_nodes, 1])\n",
    "\n",
    "        messages  = self.message_passers(state_j, edges)\n",
    "\n",
    "        # Do this to ignore messages from non-existant nodes\n",
    "        masked =  tf.math.multiply(messages, mask)\n",
    "        \n",
    "        masked = tf.reshape(masked, [tf.shape(messages)[0], n_nodes, n_nodes, node_dim])\n",
    "\n",
    "        agg_m = self.message_aggs(masked)\n",
    "        \n",
    "        updated_nodes = self.update_functions(nodes, agg_m)\n",
    "        \n",
    "        nodes_out = updated_nodes\n",
    "        # Batch norm seems not to work. \n",
    "        #nodes_out = self.batch_norm(updated_nodes)\n",
    "        \n",
    "        return nodes_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_input = tf.keras.Input(shape=(None,), name='adj_input')\n",
    "nod_input = tf.keras.Input(shape=(None,), name='nod_input')\n",
    "class MPNN(tf.keras.Model):\n",
    "    def __init__(self, n_nodes, out_int_dim, state_dim, T):\n",
    "        super(MPNN, self).__init__(self)   \n",
    "        self.T = T\n",
    "        self.embed = tf.keras.layers.Dense(units=state_dim, activation=tf.nn.relu)\n",
    "        self.MP = MP_Layer(state_dim)     \n",
    "        self.edge_regressor  = Output_Regressor(n_nodes,out_int_dim)\n",
    "        #self.batch_norm = tf.keras.layers.BatchNormalization() \n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "      \n",
    "        nodes = inputs[0]\n",
    "        edges = inputs[1]\n",
    "\n",
    "        # Get distances, and create mask wherever 0 (i.e. non-existant nodes)\n",
    "        # This also masks node self-interactions...\n",
    "        # This assumes distance is last\n",
    "        len_edges = tf.shape(edges)[-1]\n",
    "        \n",
    "        _, x = tf.split(edges, [len_edges -1, 1], 2)\n",
    "        mask =  tf.where(tf.equal(x, 0), x, tf.ones_like(x))\n",
    "        \n",
    "        # Embed node to be of the chosen node dimension (you can also just pad)\n",
    "        nodes = self.embed(nodes) \n",
    "        \n",
    "        #nodes = self.batch_norm(nodes)\n",
    "        # Run the T message passing steps\n",
    "        for mp in range(self.T):\n",
    "            nodes =  self.MP(nodes, edges, mask)\n",
    "        \n",
    "        # Regress the output values\n",
    "        con_edges = self.edge_regressor(nodes, edges)\n",
    "        \n",
    "        \n",
    "        return con_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "    reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(nums, preds)))\n",
    "\n",
    "    return reconstruction_error\n",
    "\n",
    "def log_mse(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "\n",
    "    reconstruction_error = tf.math.log(tf.reduce_mean(tf.square(tf.subtract(nums, preds))))\n",
    "\n",
    "\n",
    "    return reconstruction_error\n",
    "\n",
    "def mae(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "\n",
    "    reconstruction_error = tf.reduce_mean(tf.abs(tf.subtract(nums, preds)))\n",
    "\n",
    "\n",
    "    return reconstruction_error\n",
    "\n",
    "def log_mae(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "    reconstruction_error = tf.math.log(tf.reduce_mean(tf.abs(tf.subtract(nums, preds))))\n",
    "\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = learning_rate\n",
    "    drop = 0.1\n",
    "    epochs_drop = 20.0\n",
    "    lrate = initial_lrate * np.power(drop,  \n",
    "           np.floor((epoch)/epochs_drop))\n",
    "    tf.print(\"Learning rate: \", lrate)\n",
    "    return lrate\n",
    "\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 15, restore_best_weights=True)\n",
    "\n",
    "#lrate  =  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "#                              patience=5, min_lr=0.00001, verbose = 1)\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = MPNN(n_nodes=25, out_int_dim = 32, state_dim = 32, T = 3)\n",
    "mpnn.compile(opt, log_mae, metrics = [mae, log_mse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call network once to build weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 25), dtype=float32, numpy=\n",
       "array([[ 1.0797135e-03, -1.2848546e-02,  1.6549561e-02,  2.9463133e-02,\n",
       "         7.8990953e-03,  4.1191406e-03,  6.3671148e-03,  2.7426641e-02,\n",
       "        -1.6473975e-02,  1.0674633e-04,  9.5993858e-03,  2.3424869e-02,\n",
       "         1.5269341e-03,  1.7993692e-02, -1.8158950e-02,  2.0587347e-02,\n",
       "         5.4382146e-03,  1.2803090e-02, -1.5448740e-02,  3.3330605e-03,\n",
       "         1.8785350e-02,  6.1724260e-02, -4.6055573e-03, -2.0276092e-02,\n",
       "        -3.5873525e-02],\n",
       "       [-4.9472256e-03,  1.0687323e-02,  1.2348322e-02,  4.1257963e-04,\n",
       "        -1.3013111e-02, -1.2119235e-02, -1.4458061e-02,  2.5175735e-03,\n",
       "        -1.9541074e-02, -2.9170362e-02, -7.3225251e-03, -1.2437611e-02,\n",
       "         2.1099653e-02,  1.5739635e-02, -1.3513623e-02,  8.7389117e-03,\n",
       "         1.7870599e-03, -7.9250950e-03,  2.6071090e-02, -2.2223908e-02,\n",
       "         5.3339349e-03, -3.9729621e-02,  3.6105834e-02, -2.1069009e-02,\n",
       "        -1.0831242e-02],\n",
       "       [ 6.6495920e-04, -1.9593090e-03,  1.0514378e-02,  2.5675429e-02,\n",
       "         1.8244445e-02, -3.1848811e-04,  2.6712408e-03,  2.3709437e-02,\n",
       "        -1.2752607e-02, -7.4090846e-03,  1.5395165e-03,  2.9003236e-02,\n",
       "         6.7951297e-03,  2.1363078e-02, -1.7163418e-02,  1.9076530e-02,\n",
       "         8.9752348e-04,  2.5971852e-02, -3.6106030e-03,  2.3394255e-03,\n",
       "         2.2112776e-02,  6.1312042e-02, -9.6370075e-03, -9.1552492e-03,\n",
       "        -3.0242460e-02],\n",
       "       [ 1.5620014e-02, -1.6580813e-02,  5.0157728e-03,  5.1686787e-03,\n",
       "        -2.0942479e-02, -5.2080909e-03,  1.2537892e-02,  2.2132024e-02,\n",
       "        -1.7703066e-02, -5.5807279e-03,  9.1517093e-03,  9.2732664e-03,\n",
       "        -8.7969517e-03,  2.7286492e-02, -1.8371562e-02,  1.1265418e-02,\n",
       "         2.5910454e-02, -3.8234163e-03,  4.1277320e-03,  1.6137827e-03,\n",
       "         1.6876714e-02,  4.1289773e-02,  5.1233582e-03, -1.5001858e-02,\n",
       "        -2.6019875e-02],\n",
       "       [-7.1205194e-03, -1.6977413e-02,  8.3251921e-03,  1.4837086e-04,\n",
       "        -3.6120459e-03, -2.2046814e-02,  4.4054259e-03, -2.1024887e-03,\n",
       "         2.1644484e-02,  1.6634641e-02, -1.2974681e-02, -1.5279112e-02,\n",
       "         8.7113269e-03, -9.9873962e-03,  1.2713008e-02,  3.0286876e-03,\n",
       "        -1.5114727e-02, -1.1996977e-02,  1.4687061e-02, -1.9848974e-02,\n",
       "         1.3500702e-02,  5.0160941e-03,  1.8431034e-02, -1.4611239e-02,\n",
       "        -1.5936994e-03],\n",
       "       [-2.0652108e-02,  1.5547616e-02, -1.3811359e-02,  4.7255694e-03,\n",
       "         1.4806633e-02,  7.9127038e-03, -5.8112200e-03, -1.8363679e-04,\n",
       "         1.7906664e-02,  9.9470317e-03, -3.2693665e-03, -4.7093141e-04,\n",
       "         1.5911660e-03,  1.2116456e-02,  2.8447330e-04, -1.1717923e-02,\n",
       "         2.9021124e-03, -6.7722430e-03, -7.4929968e-03,  1.2075670e-02,\n",
       "        -1.7314369e-03, -4.9378090e-03, -1.3075348e-02, -6.5404819e-03,\n",
       "         5.0352118e-03],\n",
       "       [-2.2681510e-02,  1.0154905e-02, -1.0229121e-02,  2.0090942e-03,\n",
       "         1.3442312e-02,  9.8031806e-03, -1.7662046e-03,  5.1774085e-04,\n",
       "         1.5764674e-02,  8.0196094e-03, -8.5897767e-04,  3.3786159e-03,\n",
       "         1.1045560e-03,  1.9237176e-02,  1.3111162e-03, -7.7630719e-03,\n",
       "         2.5754014e-03, -8.1203496e-03, -2.4729900e-03,  7.0681130e-03,\n",
       "        -3.1798030e-05, -5.1289382e-03, -9.1937892e-03, -9.7573306e-03,\n",
       "         3.4392846e-03],\n",
       "       [-1.3182640e-02, -1.1934413e-02, -5.7421448e-03,  1.4065919e-02,\n",
       "        -2.2436613e-03,  5.7678055e-03,  8.1314892e-03,  2.6796088e-03,\n",
       "         2.2499975e-02,  1.9028125e-02,  5.8024814e-03,  1.5756274e-03,\n",
       "         7.9288222e-03,  7.1108090e-03,  7.3894379e-03, -3.1444859e-03,\n",
       "        -3.3507077e-04, -1.4189326e-02,  5.4196324e-03, -5.8429982e-03,\n",
       "        -8.2655903e-03,  1.1913343e-03,  7.1334746e-03, -1.1909866e-02,\n",
       "         5.4127956e-03],\n",
       "       [-2.1537848e-02,  5.5586291e-03,  4.1267443e-03, -5.3756461e-03,\n",
       "        -1.1341764e-02,  5.9244595e-04, -1.3711862e-02,  6.4719343e-03,\n",
       "         5.5543040e-03, -2.1646459e-02,  1.2852903e-02,  6.0929642e-03,\n",
       "         1.1491512e-02, -5.4537957e-03, -1.3277254e-02,  1.2869575e-02,\n",
       "        -2.7936473e-02, -6.4866627e-03,  2.1191075e-02, -2.3265558e-03,\n",
       "        -7.4201114e-03,  1.3104397e-02,  5.4132654e-03,  1.4278809e-02,\n",
       "        -1.2066422e-02],\n",
       "       [-8.4144268e-03, -1.0895688e-02,  1.2597635e-02, -2.7310383e-03,\n",
       "        -7.8276563e-03, -7.3538022e-03,  1.3841144e-03,  6.9205957e-03,\n",
       "        -7.2078044e-03, -4.0103178e-03, -1.7258560e-02,  8.2960436e-03,\n",
       "         2.0629382e-02,  7.1623735e-03, -3.2524681e-03,  1.8960773e-04,\n",
       "        -9.6143791e-03,  5.2391207e-03,  5.9173228e-03, -1.5417561e-03,\n",
       "        -8.5925087e-03, -1.0089487e-02,  1.3850989e-02, -1.0490210e-02,\n",
       "        -4.3048756e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn.call([ip_data_train[:10],amat_data_train[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      "56/56 - 68s - loss: -1.1600e+00 - mae: 0.3239 - log_mse: -1.9403e+00 - val_loss: -1.4346e+00 - val_mae: 0.2388 - val_log_mse: -2.4336e+00\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "56/56 - 54s - loss: -1.4758e+00 - mae: 0.2293 - log_mse: -2.4635e+00 - val_loss: -1.5024e+00 - val_mae: 0.2235 - val_log_mse: -2.4843e+00\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "56/56 - 55s - loss: -1.5444e+00 - mae: 0.2139 - log_mse: -2.5576e+00 - val_loss: -1.5560e+00 - val_mae: 0.2120 - val_log_mse: -2.5733e+00\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "56/56 - 54s - loss: -1.6039e+00 - mae: 0.2015 - log_mse: -2.6397e+00 - val_loss: -1.5979e+00 - val_mae: 0.2035 - val_log_mse: -2.5998e+00\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "56/56 - 55s - loss: -1.6378e+00 - mae: 0.1950 - log_mse: -2.6898e+00 - val_loss: -1.6371e+00 - val_mae: 0.1956 - val_log_mse: -2.6724e+00\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "56/56 - 56s - loss: -1.6500e+00 - mae: 0.1930 - log_mse: -2.7110e+00 - val_loss: -1.6628e+00 - val_mae: 0.1910 - val_log_mse: -2.6735e+00\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "56/56 - 56s - loss: -1.7430e+00 - mae: 0.1756 - log_mse: -2.8474e+00 - val_loss: -1.7571e+00 - val_mae: 0.1740 - val_log_mse: -2.8425e+00\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c9cd0c483839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mpnn.fit([ip_data_train,amat_data_train], y = op_data_train, batch_size = batch_size, epochs = epochs, \n\u001b[1;32m      2\u001b[0m          \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          validation_data = ([ip_data_valid,amat_data_valid],op_data_valid) )\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mpnn.fit([ip_data_train,amat_data_train], y = op_data_train, batch_size = batch_size, epochs = epochs, \n",
    "         callbacks = [lrate, stop_early], use_multiprocessing = False, initial_epoch = 0, verbose = 2, \n",
    "         validation_data = ([ip_data_valid,amat_data_valid],op_data_valid) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
